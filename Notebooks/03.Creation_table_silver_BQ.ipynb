{"cells": [{"cell_type": "markdown", "id": "0240f77d-030f-4735-8d92-49d052da8826", "metadata": {"tags": []}, "source": "# Intro"}, {"cell_type": "markdown", "id": "84c93943-4ec1-40ca-9a0d-99c68b924af3", "metadata": {}, "source": "https://stackoverflow.com/questions/39926411/provide-schema-while-reading-csv-file-as-a-dataframe-in-scala-spark"}, {"cell_type": "code", "execution_count": 1, "id": "eea971ed-3531-4354-9d2c-445a640c51ea", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "Scala language: version 2.12.18\n"}, {"data": {"text/plain": "spark = org.apache.spark.sql.SparkSession@548aecd\nbucket = dataproc-temp-us-central1-1044206227610-i54vpwyj\n"}, "metadata": {}, "output_type": "display_data", "source": "user"}, {"data": {"text/plain": "3.3.2"}, "execution_count": 1, "metadata": {}, "output_type": "execute_result"}], "source": "import org.apache.spark.sql.SparkSession\nimport org.apache.spark.sql.expressions.Window\nimport java.time.LocalTime\nimport org.apache.spark.sql.functions.udf\nimport org.apache.spark.sql.DataFrame\nimport org.apache.spark.sql.functions._\nimport org.apache.spark.sql.functions.col\nimport org.apache.spark.sql.types._\n\n// import spark.implicits._\n\nimport org.apache.spark.sql.SparkSession\n\nval spark = SparkSession\n  .builder()\n  .appName(\"Spark SQL basic example\")\n  .config(\"spark.some.config.option\", \"some-value\")\n  .getOrCreate()\n\nimport spark.sqlContext.implicits._\n\nprintln(\"Scala language: \"+util.Properties.versionString)\n\n// Use the Cloud Storage bucket for temporary BigQuery export data used\n// by the connector.\nval bucket = \"dataproc-temp-us-central1-1044206227610-i54vpwyj\"\nspark.conf.set(\"temporaryGcsBucket\", bucket)\n\n// spark.sparkContext.version\nspark.version"}, {"cell_type": "markdown", "id": "6436e4f2-beff-428b-a360-a37ce6ab89dc", "metadata": {"tags": []}, "source": "---\n\n# Flights"}, {"cell_type": "code", "execution_count": 30, "id": "43605a45-3cf0-4118-9871-ec4db9c1f6e3", "metadata": {}, "outputs": [{"data": {"text/plain": "[FL_DATE: timestamp, OP_CARRIER_AIRLINE_ID: int ... 11 more fields]"}, "execution_count": 30, "metadata": {}, "output_type": "execute_result"}], "source": "val filePath = \"gs://dataset-flight/Flights/\"\nval df_flights_raw = spark.read\n  .option(\"header\", \"true\")\n  .option(\"inferSchema\", \"true\")\n  .csv(filePath)"}, {"cell_type": "code", "execution_count": 31, "id": "f5f7f8f8-9a1c-44be-817c-66ad7b5627b7", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "17920326\n+---------------------+-----------------+-----------------+---------------+-------------+----------------+-------------+---------+-------------------+----------+\n|OP_CARRIER_AIRLINE_ID|OP_CARRIER_FL_NUM|ORIGIN_AIRPORT_ID|DEST_AIRPORT_ID|ARR_DELAY_NEW|CRS_ELAPSED_TIME|WEATHER_DELAY|NAS_DELAY|        FL_DATETIME|IS_DELAYED|\n+---------------------+-----------------+-----------------+---------------+-------------+----------------+-------------+---------+-------------------+----------+\n|                20366|             2543|            11298|          10728|            0|              70|            0|        0|2013-07-01 08:30:00|         0|\n|                20366|             6046|            10693|          12266|            0|             121|            0|        0|2013-07-01 12:42:00|         0|\n|                20436|              601|            15412|          11292|           42|             181|            0|       12|2013-07-01 18:04:00|         0|\n+---------------------+-----------------+-----------------+---------------+-------------+----------------+-------------+---------+-------------------+----------+\nonly showing top 3 rows\n\n"}, {"data": {"text/plain": "delayThreshold = 30\ndf_flights_clean = [OP_CARRIER_AIRLINE_ID: int, OP_CARRIER_FL_NUM: int ... 8 more fields]\n"}, "metadata": {}, "output_type": "display_data", "source": "user"}, {"data": {"text/plain": "[OP_CARRIER_AIRLINE_ID: int, OP_CARRIER_FL_NUM: int ... 8 more fields]"}, "execution_count": 31, "metadata": {}, "output_type": "execute_result"}], "source": "val delayThreshold = 30\n\nval df_flights_clean = df_flights_raw\n\n    // filter useless cols & rows\n    .drop(\"_c12\")\n    .where(col(\"CANCELLED\") === 0).drop(\"CANCELLED\")\n    .where(col(\"DIVERTED\") === 0).drop(\"DIVERTED\")\n    .dropDuplicates(Seq(\"FL_DATE\", \"OP_CARRIER_AIRLINE_ID\", \"OP_CARRIER_FL_NUM\", \"ORIGIN_AIRPORT_ID\"))\n\n    // get Flight date time with hours & minutes \n    .withColumn(\"PAD_CRS_DEP_TIME\", lpad(col(\"CRS_DEP_TIME\"), 4, \"0\"))\n    .withColumn(\"FL_DATETIME\", to_timestamp(concat(split(col(\"FL_DATE\"),\" \").getItem(0), lit(' '), col(\"PAD_CRS_DEP_TIME\")),\"yyyy-MM-dd HHmm\"))\n    .drop(\"PAD_CRS_DEP_TIME\", \"FL_DATE\", \"CRS_DEP_TIME\")\n\n    // change other types\n    .na.fill(0, Seq(\"NAS_DELAY\", \"WEATHER_DELAY\"))\n    .withColumn(\"NAS_DELAY\", col(\"NAS_DELAY\").cast(\"int\"))\n    .withColumn(\"WEATHER_DELAY\", col(\"WEATHER_DELAY\").cast(\"int\"))\n    .withColumn(\"CRS_ELAPSED_TIME\", col(\"CRS_ELAPSED_TIME\").cast(\"int\"))\n    .withColumn(\"ARR_DELAY_NEW\", col(\"ARR_DELAY_NEW\").cast(\"int\"))\n\n    // filter inconsistent values\n    .where(!(col(\"ARR_DELAY_NEW\") < -45))\n    .where(col(\"ARR_DELAY_NEW\") < (5.3 * 60))\n\n    // create target\n    .withColumn(\"IS_DELAYED\", when(col(\"ARR_DELAY_NEW\") >= delayThreshold and (col(\"NAS_DELAY\") >= delayThreshold or col(\"WEATHER_DELAY\") > 0), 1).otherwise(0))\n\nprintln(df_flights_clean.count())\ndf_flights_clean.show(3)"}, {"cell_type": "code", "execution_count": 32, "id": "60ee83f4-6388-4070-a26d-a29a6d2231ac", "metadata": {}, "outputs": [], "source": "df_flights_clean.write.format(\"bigquery\")\n  .option(\"table\",\"silver.flights\")\n  .save()"}, {"cell_type": "markdown", "id": "3cee22ff-d3a1-4bf8-8196-5236856b1ab9", "metadata": {}, "source": "---"}, {"cell_type": "markdown", "id": "8b0b0396-050c-4941-810c-da4fbe9dec69", "metadata": {}, "source": "# Weather"}, {"cell_type": "code", "execution_count": 2, "id": "b168633e-f8ff-4a46-bf72-5cefb651a352", "metadata": {}, "outputs": [{"data": {"text/plain": "weatherPath = gs://dataset-flight/Weather/\nweatherSchema = StructType(StructField(WBAN,IntegerType,true),StructField(Date,IntegerType,true),StructField(Time,IntegerType,true),StructField(StationType,IntegerType,true),StructField(SkyCondition,StringType,true),StructField(SkyConditionFlag,StringType,true),StructField(Visibility,StringType,true),StructField(VisibilityFlag,StringType,true),StructField(WeatherType,StringType,true),StructField(WeatherTypeFlag,StringType,true),StructField(DryBulbFarenheit,IntegerType,true),StructField(DryBulbFarenheitFlag,StringType,true),StructField(DryBulbCelsius,FloatType,true),StructField(DryBulbCelsiusFlag,StringType,true),StructField(WetBulbFarenheit,IntegerType,true),StructField(WetBulbFarenheitFlag,StringT...\n"}, "metadata": {}, "output_type": "display_data", "source": "user"}, {"data": {"text/plain": "StructType(StructField(WBAN,IntegerType,true),StructField(Date,IntegerType,true),StructField(Time,IntegerType,true),StructField(StationType,IntegerType,true),StructField(SkyCondition,StringType,true),StructField(SkyConditionFlag,StringType,true),StructField(Visibility,StringType,true),StructField(VisibilityFlag,StringType,true),StructField(WeatherType,StringType,true),StructField(WeatherTypeFlag,StringType,true),StructField(DryBulbFarenheit,IntegerType,true),StructField(DryBulbFarenheitFlag,StringType,true),StructField(DryBulbCelsius,FloatType,true),StructField(DryBulbCelsiusFlag,StringType,true),StructField(WetBulbFarenheit,IntegerType,true),StructField(WetBulbFarenheitFlag,StringT..."}, "execution_count": 2, "metadata": {}, "output_type": "execute_result"}], "source": "val weatherPath = \"gs://dataset-flight/Weather/\"\n\nval weatherSchema = StructType(Array(    \n    StructField(\"WBAN\", IntegerType, true),\n    StructField(\"Date\", IntegerType, true),\n    StructField(\"Time\", IntegerType, true),\n    StructField(\"StationType\", IntegerType, true),\n    StructField(\"SkyCondition\", StringType, true),\n    StructField(\"SkyConditionFlag\", StringType, true),\n    StructField(\"Visibility\", StringType, true), // enlever espace puis caster en int\n    StructField(\"VisibilityFlag\", StringType, true),\n    StructField(\"WeatherType\", StringType, true),\n    StructField(\"WeatherTypeFlag\", StringType, true),\n    StructField(\"DryBulbFarenheit\", IntegerType, true),\n    StructField(\"DryBulbFarenheitFlag\", StringType, true),\n    StructField(\"DryBulbCelsius\", FloatType, true),\n    StructField(\"DryBulbCelsiusFlag\", StringType, true),\n    StructField(\"WetBulbFarenheit\", IntegerType, true),\n    StructField(\"WetBulbFarenheitFlag\", StringType, true),\n    StructField(\"WetBulbCelsius\", FloatType, true),\n    StructField(\"WetBulbCelsiusFlag\", StringType, true),\n    StructField(\"DewPointFarenheit\", IntegerType, true),\n    StructField(\"DewPointFarenheitFlag\", StringType, true),\n    StructField(\"DewPointCelsius\", FloatType, true),\n    StructField(\"DewPointCelsiusFlag\", StringType, true),\n    StructField(\"RelativeHumidity\", StringType, true), // a convertir en int apr\u00e8s space\n    StructField(\"RelativeHumidityFlag\", StringType, true),\n    StructField(\"WindSpeed\", IntegerType, true),\n    StructField(\"WindSpeedFlag\", StringType, true),\n    StructField(\"WindDirection\", IntegerType, true),\n    StructField(\"WindDirectionFlag\", StringType, true),\n    StructField(\"ValueForWindCharacter\", IntegerType, true),\n    StructField(\"ValueForWindCharacterFlag\", StringType, true),\n    StructField(\"StationPressure\", FloatType, true),\n    StructField(\"StationPressureFlag\", StringType, true),\n    StructField(\"PressureTendency\", IntegerType, true),\n    StructField(\"PressureTendencyFlag\", StringType, true),\n    StructField(\"PressureChange\", IntegerType, true),\n    StructField(\"PressureChangeFlag\", StringType, true),\n    StructField(\"SeaLevelPressure\", FloatType, true),\n    StructField(\"SeaLevelPressureFlag\", StringType, true),\n    StructField(\"RecordType\", StringType, true),\n    StructField(\"RecordTypeFlag\", StringType, true),\n    StructField(\"HourlyPrecip\", FloatType, true),\n    StructField(\"HourlyPrecipFlag\", StringType, true),\n    StructField(\"Altimeter\", FloatType, true),\n    StructField(\"AltimeterFlag\", StringType, true),\n))\n\n\nval df_weather_raw = spark.read.format(\"csv\")\n    .option(\"header\", \"true\")\n    .option(\"delimited\", \",\")\n    .schema(weatherSchema)\n    .option(\"treatEmptyValuesAsNulls\",\"true\")\n    .option(\"nullValue\", null)\n    .option(\"emptyValue\", null)\n    .load(weatherPath)"}, {"cell_type": "code", "execution_count": 3, "id": "b375c72d-6e88-48f1-8806-d1b93ac9b434", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "32631312\n44\n"}], "source": "println(df_weather_raw.count())\nprintln(df_weather_raw.columns.size)"}, {"cell_type": "code", "execution_count": 4, "id": "594b441d-f911-4416-a58a-c1e4028b780e", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "32631312\n24\n"}, {"data": {"text/plain": "df_weather_clean = [WBAN: int, Date: int ... 22 more fields]\n"}, "metadata": {}, "output_type": "display_data", "source": "user"}, {"data": {"text/plain": "[WBAN: int, Date: int ... 22 more fields]"}, "execution_count": 4, "metadata": {}, "output_type": "execute_result"}], "source": "val df_weather_clean = df_weather_raw\n    .drop(df_weather_raw.columns.filter(colName => colName.endsWith(\"Flag\")) : _*)\n    .withColumn(\"Visibility\", trim(col(\"Visibility\")).cast(\"int\"))\n    .withColumn(\"WindSpeed\", trim(col(\"WindSpeed\")).cast(\"int\"))\n    .withColumn(\"RelativeHumidity\", trim(col(\"RelativeHumidity\")).cast(\"int\"))\n\n\nprintln(df_weather_clean.count())\nprintln(df_weather_clean.columns.size)"}, {"cell_type": "code", "execution_count": 5, "id": "243f8c89-7e6d-4321-9e09-a350fb890eeb", "metadata": {}, "outputs": [], "source": "df_weather_clean.write.format(\"bigquery\")\n  .option(\"table\",\"silver.weather\")\n  .save()"}, {"cell_type": "code", "execution_count": 11, "id": "a07806b4-f050-4491-904d-6b7a6cc886c1", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "+----+--------+----+-----------+------------+----------+-----------+----------------+--------------+----------------+--------------+-----------------+---------------+\n|WBAN|    Date|Time|StationType|SkyCondition|Visibility|WeatherType|DryBulbFarenheit|DryBulbCelsius|WetBulbFarenheit|WetBulbCelsius|DewPointFarenheit|DewPointCelsius|\n+----+--------+----+-----------+------------+----------+-----------+----------------+--------------+----------------+--------------+-----------------+---------------+\n|3011|20120101|  15|          0|         CLR|        10|           |              23|          -5.0|              15|          -9.5|               -9|          -23.0|\n|3011|20120101|  35|          0|         CLR|        10|           |              21|          -6.0|              14|         -10.2|               -9|          -23.0|\n|3011|20120101|  55|          0|         CLR|        10|           |              21|          -6.0|              13|         -10.5|             null|          -25.0|\n+----+--------+----+-----------+------------+----------+-----------+----------------+--------------+----------------+--------------+-----------------+---------------+\nonly showing top 3 rows\n\n"}], "source": "df_weather_clean.select(\"WBAN\", \"Date\", \"Time\", \"StationType\", \"SkyCondition\", \"Visibility\", \"WeatherType\", \"DryBulbFarenheit\", \"DryBulbCelsius\", \"WetBulbFarenheit\" ,\"WetBulbCelsius\", \"DewPointFarenheit\", \"DewPointCelsius\")show(3)"}, {"cell_type": "code", "execution_count": 12, "id": "77b4df38-32eb-4127-83b3-87e2965d3d31", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "+----------------+---------+-------------+---------------------+---------------+----------------+--------------+----------------+----------+------------+---------+\n|RelativeHumidity|WindSpeed|WindDirection|ValueForWindCharacter|StationPressure|PressureTendency|PressureChange|SeaLevelPressure|RecordType|HourlyPrecip|Altimeter|\n+----------------+---------+-------------+---------------------+---------------+----------------+--------------+----------------+----------+------------+---------+\n|              24|     null|          120|                 null|           21.7|            null|          null|            null|        AA|        null|    30.43|\n|              26|     null|          130|                 null|           21.7|            null|          null|            null|        AA|        null|    30.43|\n|              21|     null|            0|                 null|          21.71|            null|          null|            null|        AA|        null|    30.44|\n+----------------+---------+-------------+---------------------+---------------+----------------+--------------+----------------+----------+------------+---------+\nonly showing top 3 rows\n\n"}], "source": "df_weather_clean.select(\"RelativeHumidity\", \"WindSpeed\", \"WindDirection\", \"ValueForWindCharacter\", \"StationPressure\", \"PressureTendency\", \"PressureChange\", \"SeaLevelPressure\", \"RecordType\", \"HourlyPrecip\", \"Altimeter\")show(3)"}, {"cell_type": "markdown", "id": "1be79015-f408-4501-9053-0bcad41d4465", "metadata": {}, "source": "---\nWBAN"}, {"cell_type": "code", "execution_count": 13, "id": "3218d79e-9b7e-4df6-9dd5-cf195a3a55c1", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "+---------+-----+--------+\n|AirportID| WBAN|TimeZone|\n+---------+-----+--------+\n|    10685|54831|      -6|\n|    14871|24232|      -8|\n|    10620|24033|      -7|\n|    14747|24233|      -8|\n|    11252|12834|      -5|\n+---------+-----+--------+\nonly showing top 5 rows\n\n"}, {"data": {"text/plain": "airportsPath = gs://dataset-flight/wban_airport_timezone.csv\ndf_airports = [AirportID: int, WBAN: int ... 1 more field]\n"}, "metadata": {}, "output_type": "display_data", "source": "user"}, {"data": {"text/plain": "[AirportID: int, WBAN: int ... 1 more field]"}, "execution_count": 13, "metadata": {}, "output_type": "execute_result"}], "source": "val airportsPath = \"gs://dataset-flight/wban_airport_timezone.csv\"\nval df_airports = spark.read\n  .option(\"header\", \"true\")\n  .option(\"inferSchema\", \"true\")\n  .csv(airportsPath)\n\ndf_airports.show(5)"}, {"cell_type": "code", "execution_count": 14, "id": "af46293b-88d2-419c-91b9-c456b23512cf", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "root\n |-- AirportID: integer (nullable = true)\n |-- WBAN: integer (nullable = true)\n |-- TimeZone: integer (nullable = true)\n\n"}], "source": "df_airports.printSchema()"}], "metadata": {"kernelspec": {"display_name": "Apache Toree - Scala", "language": "scala", "name": "apache_toree_scala"}, "language_info": {"codemirror_mode": "text/x-scala", "file_extension": ".scala", "mimetype": "text/x-scala", "name": "scala", "pygments_lexer": "scala", "version": "2.12.15"}}, "nbformat": 4, "nbformat_minor": 5}