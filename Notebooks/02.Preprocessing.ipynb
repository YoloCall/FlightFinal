{"cells": [{"cell_type": "markdown", "id": "0240f77d-030f-4735-8d92-49d052da8826", "metadata": {"tags": []}, "source": "# Intro"}, {"cell_type": "markdown", "id": "84c93943-4ec1-40ca-9a0d-99c68b924af3", "metadata": {}, "source": "https://stackoverflow.com/questions/39926411/provide-schema-while-reading-csv-file-as-a-dataframe-in-scala-spark"}, {"cell_type": "code", "execution_count": 1, "id": "eea971ed-3531-4354-9d2c-445a640c51ea", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "Scala language: version 2.12.18\n"}, {"data": {"text/plain": "spark = org.apache.spark.sql.SparkSession@6bd8170\n"}, "metadata": {}, "output_type": "display_data", "source": "user"}, {"data": {"text/plain": "3.3.2"}, "execution_count": 1, "metadata": {}, "output_type": "execute_result"}], "source": "import org.apache.spark.sql.SparkSession\nimport org.apache.spark.sql.expressions.Window\nimport java.time.LocalTime\nimport org.apache.spark.sql.functions.udf\nimport org.apache.spark.sql.DataFrame\nimport org.apache.spark.sql.functions._\nimport org.apache.spark.sql.functions.col\nimport org.apache.spark.sql.types._\n\n// import spark.implicits._\n\nimport org.apache.spark.sql.SparkSession\n\nval spark = SparkSession\n  .builder()\n  .appName(\"Spark SQL basic example\")\n  .config(\"spark.some.config.option\", \"some-value\")\n  .getOrCreate()\n\nimport spark.sqlContext.implicits._\n\nprintln(\"Scala language: \"+util.Properties.versionString)\n\n// spark.sparkContext.version\nspark.version"}, {"cell_type": "markdown", "id": "6436e4f2-beff-428b-a360-a37ce6ab89dc", "metadata": {"tags": []}, "source": "---\n\n# Flights"}, {"cell_type": "code", "execution_count": 3, "id": "43605a45-3cf0-4118-9871-ec4db9c1f6e3", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "18286055\n+-------------------+---------------------+-----------------+-----------------+---------------+------------+-------------+---------+--------+----------------+-------------+---------+----+\n|            FL_DATE|OP_CARRIER_AIRLINE_ID|OP_CARRIER_FL_NUM|ORIGIN_AIRPORT_ID|DEST_AIRPORT_ID|CRS_DEP_TIME|ARR_DELAY_NEW|CANCELLED|DIVERTED|CRS_ELAPSED_TIME|WEATHER_DELAY|NAS_DELAY|_c12|\n+-------------------+---------------------+-----------------+-----------------+---------------+------------+-------------+---------+--------+----------------+-------------+---------+----+\n|2013-07-01 00:00:00|                20363|             3407|            11433|          13342|        1040|          0.0|      0.0|     0.0|            79.0|         null|     null|null|\n|2013-07-01 00:00:00|                20363|             3409|            11433|          12266|        1227|          0.0|      0.0|     0.0|           175.0|         null|     null|null|\n|2013-07-01 00:00:00|                20363|             3848|            13485|          11433|         900|          2.0|      0.0|     0.0|            77.0|         null|     null|null|\n+-------------------+---------------------+-----------------+-----------------+---------------+------------+-------------+---------+--------+----------------+-------------+---------+----+\nonly showing top 3 rows\n\n"}, {"data": {"text/plain": "filePath = gs://dataset-flight/Flights/\ndf_flights_raw = [FL_DATE: timestamp, OP_CARRIER_AIRLINE_ID: int ... 11 more fields]\n"}, "metadata": {}, "output_type": "display_data", "source": "user"}, {"data": {"text/plain": "[FL_DATE: timestamp, OP_CARRIER_AIRLINE_ID: int ... 11 more fields]"}, "execution_count": 3, "metadata": {}, "output_type": "execute_result"}], "source": "val filePath = \"gs://dataset-flight/Flights/\"\nval df_flights_raw = spark.read\n  .option(\"header\", \"true\")\n  .option(\"inferSchema\", \"true\")\n  .csv(filePath)\n\nprintln(df_flights_raw.count())\ndf_flights_raw.show(3)"}, {"cell_type": "markdown", "id": "eda71717-fc19-4d35-a0d3-e6ccc7a61a5a", "metadata": {}, "source": "486133 -> 18286055 pour toutes les csv"}, {"cell_type": "markdown", "id": "76e43655-193b-4da8-a65a-ca40c58baa78", "metadata": {}, "source": "preprocessing"}, {"cell_type": "code", "execution_count": 4, "id": "fbf31eac-03c4-48bc-a847-cb3d0a28c7e5", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "17920326\n+-------------------+---------------------+-----------------+-----------------+---------------+------------+-------------+----------------+-------------+---------+----------+\n|            FL_DATE|OP_CARRIER_AIRLINE_ID|OP_CARRIER_FL_NUM|ORIGIN_AIRPORT_ID|DEST_AIRPORT_ID|CRS_DEP_TIME|ARR_DELAY_NEW|CRS_ELAPSED_TIME|WEATHER_DELAY|NAS_DELAY|IS_DELAYED|\n+-------------------+---------------------+-----------------+-----------------+---------------+------------+-------------+----------------+-------------+---------+----------+\n|2013-03-01 00:00:00|                20363|             4114|            11433|          11423|        1625|            0|             116|         null|        0|         0|\n|2013-03-01 00:00:00|                20363|             4255|            11042|          11433|        1015|            0|              65|         null|        0|         0|\n|2013-03-01 00:00:00|                19790|             1878|            12217|          10397|         630|            0|              74|         null|        0|         0|\n+-------------------+---------------------+-----------------+-----------------+---------------+------------+-------------+----------------+-------------+---------+----------+\nonly showing top 3 rows\n\n"}, {"data": {"text/plain": "delayThreshold = 30\ndf_flights_clean = [FL_DATE: timestamp, OP_CARRIER_AIRLINE_ID: int ... 9 more fields]\n"}, "metadata": {}, "output_type": "display_data", "source": "user"}, {"data": {"text/plain": "[FL_DATE: timestamp, OP_CARRIER_AIRLINE_ID: int ... 9 more fields]"}, "execution_count": 4, "metadata": {}, "output_type": "execute_result"}], "source": "val delayThreshold = 30\n\nval df_flights_clean = df_flights_raw\n    .drop(\"_c12\") // 478k\n    .where(col(\"CANCELLED\") === 0).drop(\"CANCELLED\")\n    .where(col(\"DIVERTED\") === 0).drop(\"DIVERTED\") // 478k\n    .na.fill(0, Seq(\"NAS_DELAY\"))\n    .withColumn(\"NAS_DELAY\", col(\"NAS_DELAY\").cast(\"int\"))\n    .dropDuplicates(Seq(\"FL_DATE\", \"OP_CARRIER_AIRLINE_ID\", \"OP_CARRIER_FL_NUM\", \"ORIGIN_AIRPORT_ID\")) // 437k\n    .withColumn(\"CRS_ELAPSED_TIME\", col(\"CRS_ELAPSED_TIME\").cast(\"int\")) // float -> int\n    .withColumn(\"ARR_DELAY_NEW\", col(\"ARR_DELAY_NEW\").cast(\"int\"))\n    .where(!(col(\"ARR_DELAY_NEW\") < -45)) // n'arrive jamais 45min en avance\n    .where(col(\"ARR_DELAY_NEW\") < (5.3 * 60)) // 437k\n    .withColumn(\"IS_DELAYED\", when(col(\"ARR_DELAY_NEW\") >= delayThreshold and (col(\"NAS_DELAY\") >= delayThreshold or col(\"WEATHER_DELAY\") > 0), 1).otherwise(0))\n\nprintln(df_flights_clean.count())\n\ndf_flights_clean.show(3)"}, {"cell_type": "code", "execution_count": 5, "id": "0d7d9613-2668-43f8-809f-4c740e28783e", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "+--------------------+--------------------+\n|             summary|          IS_DELAYED|\n+--------------------+--------------------+\n|               count|            17920326|\n|approx_count_dist...|                   2|\n|                mean|0.030714340799380548|\n|              stddev| 0.17254266640438876|\n|                 min|                   0|\n|                 25%|                   0|\n|                 50%|                   0|\n|                 75%|                   0|\n|                 95%|                   0|\n|                 max|                   1|\n+--------------------+--------------------+\n\n"}], "source": "df_flights_clean.select(\"IS_DELAYED\")\n    .summary(\"count\", \"approx_count_distinct\", \"mean\", \"stddev\", \"min\", \"25%\", \"50%\", \"75%\", \"95%\", \"max\").show()"}, {"cell_type": "code", "execution_count": 6, "id": "fe7532da-36e0-4914-bf55-840fea2ab31e", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "+--------------------+-----------------+\n|             summary|    WEATHER_DELAY|\n+--------------------+-----------------+\n|               count|          3524963|\n|approx_count_dist...|              836|\n|                mean|2.338359863635448|\n|              stddev|17.56329940409019|\n|                 min|              0.0|\n|                 25%|              0.0|\n|                 50%|              0.0|\n|                 75%|              0.0|\n|                 95%|              3.0|\n|                 max|           1615.0|\n+--------------------+-----------------+\n\n"}], "source": "df_flights_raw.select(\"WEATHER_DELAY\")\n    .summary(\"count\", \"approx_count_distinct\", \"mean\", \"stddev\", \"min\", \"25%\", \"50%\", \"75%\", \"95%\", \"max\").show()"}, {"cell_type": "code", "execution_count": 7, "id": "fdf3985f-2f7f-49c4-883e-04ac40d19169", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "root\n |-- FL_DATE: timestamp (nullable = true)\n |-- OP_CARRIER_AIRLINE_ID: integer (nullable = true)\n |-- OP_CARRIER_FL_NUM: integer (nullable = true)\n |-- ORIGIN_AIRPORT_ID: integer (nullable = true)\n |-- DEST_AIRPORT_ID: integer (nullable = true)\n |-- CRS_DEP_TIME: integer (nullable = true)\n |-- ARR_DELAY_NEW: integer (nullable = true)\n |-- CRS_ELAPSED_TIME: integer (nullable = true)\n |-- WEATHER_DELAY: double (nullable = true)\n |-- NAS_DELAY: integer (nullable = true)\n |-- IS_DELAYED: integer (nullable = false)\n\n"}], "source": "df_flights_clean.printSchema()"}, {"cell_type": "code", "execution_count": 6, "id": "f2491c18-f0ca-4f66-b890-339eea1f47e6", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "root\n |-- FL_DATE: timestamp (nullable = true)\n |-- OP_CARRIER_AIRLINE_ID: integer (nullable = true)\n |-- OP_CARRIER_FL_NUM: integer (nullable = true)\n |-- ORIGIN_AIRPORT_ID: integer (nullable = true)\n |-- DEST_AIRPORT_ID: integer (nullable = true)\n |-- CRS_DEP_TIME: integer (nullable = true)\n |-- ARR_DELAY_NEW: integer (nullable = true)\n |-- CRS_ELAPSED_TIME: integer (nullable = true)\n |-- WEATHER_DELAY: double (nullable = true)\n |-- NAS_DELAY: integer (nullable = true)\n\n"}], "source": "df_flights_clean.printSchema()"}, {"cell_type": "markdown", "id": "f0401a85-ebd3-4d02-a8a6-d8f74b769a19", "metadata": {}, "source": "nas_delay = la grande majorit\u00e9 \u00e0 NULL sinon 0:"}, {"cell_type": "code", "execution_count": 8, "id": "b892a8f0-abdb-44da-884f-522a6f1160ce", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "+--------------------+------------------+\n|             summary|         NAS_DELAY|\n+--------------------+------------------+\n|               count|           3524963|\n|approx_count_dist...|               714|\n|                mean|13.269710065041817|\n|              stddev| 26.91482091789664|\n|                 min|               0.0|\n|                 25%|               0.0|\n|                 50%|               3.0|\n|                 75%|              17.0|\n|                 max|            1439.0|\n+--------------------+------------------+\n\n"}], "source": "df_flights_raw.select(\"NAS_DELAY\")\n    .summary(\"count\", \"approx_count_distinct\", \"mean\", \"stddev\", \"min\", \"25%\", \"50%\", \"75%\", \"max\").show()"}, {"cell_type": "markdown", "id": "6f7267bc-1e67-40d8-a062-0995769d418f", "metadata": {}, "source": "---"}, {"cell_type": "markdown", "id": "717a8c10-d288-4c43-992c-2d4a7759bbb0", "metadata": {}, "source": "une fois les vols filtr\u00e9s (cancelled, diverted...), statistiques en heures:"}, {"cell_type": "code", "execution_count": 8, "id": "8d86c902-50ab-4bca-bb1f-0afbfa53cfc8", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "+-------+------------+----------------+-------------+-------------+\n|summary|CRS_DEP_TIME|CRS_ELAPSED_TIME|ARR_DELAY_NEW|WEATHER_DELAY|\n+-------+------------+----------------+-------------+-------------+\n|   mean|        22.0|             2.3|          0.1|          0.0|\n| stddev|         7.7|             1.2|          0.4|          0.4|\n|    min|         0.1|             0.4|          0.0|          0.0|\n|    25%|        15.4|             1.4|          0.0|          0.0|\n|    50%|        21.9|             2.0|          0.0|          0.0|\n|    75%|        28.6|             2.8|          0.0|          0.0|\n|    90%|        32.4|             3.9|          0.2|          0.0|\n|    95%|        34.3|             4.8|          0.4|          0.2|\n|    max|        39.3|            11.1|         24.2|         19.7|\n+-------+------------+----------------+-------------+-------------+\n\n"}, {"data": {"text/plain": "df_temp = [FL_DATE: timestamp, OP_CARRIER_AIRLINE_ID: int ... 7 more fields]\n"}, "metadata": {}, "output_type": "display_data", "source": "user"}, {"data": {"text/plain": "[FL_DATE: timestamp, OP_CARRIER_AIRLINE_ID: int ... 7 more fields]"}, "execution_count": 8, "metadata": {}, "output_type": "execute_result"}], "source": "val df_temp = df_flights_raw\n    .drop(\"_c12\") // 478k\n    .where(col(\"CANCELLED\") === 0).drop(\"CANCELLED\")\n    .where(col(\"DIVERTED\") === 0).drop(\"DIVERTED\") // 478k\n    .where(col(\"NAS_DELAY\").isNull || col(\"NAS_DELAY\") === 0).drop(\"NAS_DELAY\") // 437k\n    .dropDuplicates(Seq(\"FL_DATE\", \"OP_CARRIER_AIRLINE_ID\", \"OP_CARRIER_FL_NUM\", \"ORIGIN_AIRPORT_ID\")) // 437k\n    .withColumn(\"CRS_ELAPSED_TIME\", col(\"CRS_ELAPSED_TIME\").cast(\"int\")) // float -> int\n    .withColumn(\"ARR_DELAY_NEW\", col(\"ARR_DELAY_NEW\").cast(\"int\"))\n    .where(!(col(\"ARR_DELAY_NEW\") < -45)) // n'arrive jamais 45min en avance\n\ndf_temp\n    .select(\"CRS_DEP_TIME\", \"CRS_ELAPSED_TIME\", \"ARR_DELAY_NEW\", \"WEATHER_DELAY\")\n    .summary(\"mean\", \"stddev\", \"min\", \"25%\", \"50%\", \"75%\", \"90%\", \"95%\", \"max\")\n    .withColumn(\"CRS_DEP_TIME\", round(col(\"CRS_DEP_TIME\") / 60, 1))\n    .withColumn(\"CRS_ELAPSED_TIME\", round(col(\"CRS_ELAPSED_TIME\") / 60, 1))\n    .withColumn(\"ARR_DELAY_NEW\", round(col(\"ARR_DELAY_NEW\") / 60, 1))\n    .withColumn(\"WEATHER_DELAY\", round(col(\"WEATHER_DELAY\") / 60, 1))\n    .show()"}, {"cell_type": "markdown", "id": "25f1e6fe-8fe5-4510-b8e7-688a7dc670ea", "metadata": {}, "source": "- 25% des vols sont programm\u00e9s entre 00H00 et 15H00\n- 25% des vols sont programm\u00e9s entre 15H00 et 22H00\n- 25% des vols sont programm\u00e9s entre 22H00 et 04H00 du matin le lendemain\n\nconcernant la dur\u00e9e de vols:\n- 5% des vols ont une dur\u00e9e pr\u00e9visionelle de plus de 5h, le maximum \u00e9tant une dur\u00e9e pr\u00e9visionnelle de 11h.\n\npour ce qui est des retards:\n- 75% des vols sont a l'heure (ARR_DELAY \u00e0 zero)\n- la moyenne des retard est de 6min (0.1h)\n- 90% des vols ont moins de 12 min de retard\n\nconcernant la ponctualit\u00e9 au d\u00e9part ou a l'arriv\u00e9e: celles ci sont de l'ordre de 80%:\nhttps://www.lefigaro.fr/voyages/conseils/ponctualite-des-avions-les-aeroports-francais-sont-toujours-a-la-traine-20230728\n\nsachant que la dur\u00e9e des vols ne peut pas d\u00e9passer de plus de 3 ou 4h (pour les vols courts) et 5 ou 6h (pour les vols longs) pour des questions de r\u00e9serve de carburant limit\u00e9es, les ARR_DELAY_NEW de plus de 5h doivent forc\u00e9ment soit \u00eatre du \u00e0 des d\u00e9parts repouss\u00e9s ou des valeurs erron\u00e9es. Or nous ne connaissons pas de combien de temps le d\u00e9collage a \u00e9t\u00e9 repouss\u00e9s, mais ils y en a forc\u00e9ment vu que des CRS_DEP_TIME d\u00e9passent les 24h ! __Supprimons les arrival delay et weather delay trop importants de respectivement plus de 2.4 et 2.2h. --> OUTLIERS __"}, {"cell_type": "code", "execution_count": 11, "id": "15c12f81-06fa-4508-984f-aea2dd46a98c", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "+-------+-------------+-------------+\n|summary|ARR_DELAY_NEW|WEATHER_DELAY|\n+-------+-------------+-------------+\n|    90%|          0.2|          0.0|\n|    95%|          0.4|          0.2|\n|    97%|          0.8|          0.4|\n|    99%|          1.7|          1.5|\n|  99.5%|          2.4|          2.2|\n| 99.95%|          5.3|          4.4|\n|    max|         24.2|         19.7|\n+-------+-------------+-------------+\n\n"}], "source": "df_temp\n    .select(\"ARR_DELAY_NEW\", \"WEATHER_DELAY\")\n    .summary(\"90%\", \"95%\", \"97%\", \"99%\", \"99.5%\", \"99.95%\", \"max\")\n    .withColumn(\"ARR_DELAY_NEW\", round(col(\"ARR_DELAY_NEW\") / 60, 1))\n    .withColumn(\"WEATHER_DELAY\", round(col(\"WEATHER_DELAY\") / 60, 1))\n    .show()"}, {"cell_type": "markdown", "id": "3cee22ff-d3a1-4bf8-8196-5236856b1ab9", "metadata": {}, "source": "---"}, {"cell_type": "markdown", "id": "8b0b0396-050c-4941-810c-da4fbe9dec69", "metadata": {}, "source": "# Weather"}, {"cell_type": "code", "execution_count": 3, "id": "b168633e-f8ff-4a46-bf72-5cefb651a352", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "4192912\n44\n"}, {"data": {"text/plain": "weatherPath = gs://dataset-flight/Weather/201201hourly.txt\nweatherSchema = StructType(StructField(WBAN,IntegerType,true),StructField(Date,IntegerType,true),StructField(Time,IntegerType,true),StructField(StationType,IntegerType,true),StructField(SkyCondition,StringType,true),StructField(SkyConditionFlag,StringType,true),StructField(Visibility,StringType,true),StructField(VisibilityFlag,StringType,true),StructField(WeatherType,StringType,true),StructField(WeatherTypeFlag,StringType,true),StructField(DryBulbFarenheit,IntegerType,true),StructField(DryBulbFarenheitFlag,StringType,true),StructField(DryBulbCelsius,FloatType,true),StructField(DryBulbCelsiusFlag,StringType,true),StructField(WetBulbFarenheit,IntegerType,true),StructField(WetBulbFaren...\n"}, "metadata": {}, "output_type": "display_data", "source": "user"}, {"data": {"text/plain": "StructType(StructField(WBAN,IntegerType,true),StructField(Date,IntegerType,true),StructField(Time,IntegerType,true),StructField(StationType,IntegerType,true),StructField(SkyCondition,StringType,true),StructField(SkyConditionFlag,StringType,true),StructField(Visibility,StringType,true),StructField(VisibilityFlag,StringType,true),StructField(WeatherType,StringType,true),StructField(WeatherTypeFlag,StringType,true),StructField(DryBulbFarenheit,IntegerType,true),StructField(DryBulbFarenheitFlag,StringType,true),StructField(DryBulbCelsius,FloatType,true),StructField(DryBulbCelsiusFlag,StringType,true),StructField(WetBulbFarenheit,IntegerType,true),StructField(WetBulbFaren..."}, "execution_count": 3, "metadata": {}, "output_type": "execute_result"}], "source": "val weatherPath = \"gs://dataset-flight/Weather/201201hourly.txt\"\n\nval weatherSchema = StructType(Array(    \n    StructField(\"WBAN\", IntegerType, true),\n    StructField(\"Date\", IntegerType, true),\n    StructField(\"Time\", IntegerType, true),\n    StructField(\"StationType\", IntegerType, true),\n    StructField(\"SkyCondition\", StringType, true),\n    StructField(\"SkyConditionFlag\", StringType, true),\n    StructField(\"Visibility\", StringType, true), // enlever espace puis caster en int\n    StructField(\"VisibilityFlag\", StringType, true),\n    StructField(\"WeatherType\", StringType, true),\n    StructField(\"WeatherTypeFlag\", StringType, true),\n    StructField(\"DryBulbFarenheit\", IntegerType, true),\n    StructField(\"DryBulbFarenheitFlag\", StringType, true),\n    StructField(\"DryBulbCelsius\", FloatType, true),\n    StructField(\"DryBulbCelsiusFlag\", StringType, true),\n    StructField(\"WetBulbFarenheit\", IntegerType, true),\n    StructField(\"WetBulbFarenheitFlag\", StringType, true),\n    StructField(\"WetBulbCelsius\", FloatType, true),\n    StructField(\"WetBulbCelsiusFlag\", StringType, true),\n    StructField(\"DewPointFarenheit\", IntegerType, true),\n    StructField(\"DewPointFarenheitFlag\", StringType, true),\n    StructField(\"DewPointCelsius\", FloatType, true),\n    StructField(\"DewPointCelsiusFlag\", StringType, true),\n    StructField(\"RelativeHumidity\", StringType, true), // a convertir en int apr\u00e8s space\n    StructField(\"RelativeHumidityFlag\", StringType, true),\n    StructField(\"WindSpeed\", IntegerType, true),\n    StructField(\"WindSpeedFlag\", StringType, true),\n    StructField(\"WindDirection\", IntegerType, true),\n    StructField(\"WindDirectionFlag\", StringType, true),\n    StructField(\"ValueForWindCharacter\", IntegerType, true),\n    StructField(\"ValueForWindCharacterFlag\", StringType, true),\n    StructField(\"StationPressure\", FloatType, true),\n    StructField(\"StationPressureFlag\", StringType, true),\n    StructField(\"PressureTendency\", IntegerType, true),\n    StructField(\"PressureTendencyFlag\", StringType, true),\n    StructField(\"PressureChange\", IntegerType, true),\n    StructField(\"PressureChangeFlag\", StringType, true),\n    StructField(\"SeaLevelPressure\", FloatType, true),\n    StructField(\"SeaLevelPressureFlag\", StringType, true),\n    StructField(\"RecordType\", StringType, true),\n    StructField(\"RecordTypeFlag\", StringType, true),\n    StructField(\"HourlyPrecip\", FloatType, true),\n    StructField(\"HourlyPrecipFlag\", StringType, true),\n    StructField(\"Altimeter\", FloatType, true),\n    StructField(\"AltimeterFlag\", StringType, true),\n))\n\n\nval df_weather_raw = spark.read.format(\"csv\")\n    .option(\"header\", \"true\")\n    .option(\"delimited\", \",\")\n    .schema(weatherSchema)\n    .option(\"treatEmptyValuesAsNulls\",\"true\")\n    .option(\"nullValue\", null)\n    .option(\"emptyValue\", null)\n    .load(weatherPath)\n\n\nprintln(df_weather_raw.count())\nprintln(df_weather_raw.columns.size)\n// df_weather_raw.printSchema()"}, {"cell_type": "code", "execution_count": null, "id": "9f0ba510-5cc0-49ce-8afd-ec253adab8e0", "metadata": {}, "outputs": [], "source": "    // .drop(\"_c12\") // 478k\n    // .where(col(\"CANCELLED\") === 0).drop(\"CANCELLED\")\n    // .where(col(\"DIVERTED\") === 0).drop(\"DIVERTED\") // 478k\n    // .where(col(\"NAS_DELAY\").isNull || col(\"NAS_DELAY\") === 0).drop(\"NAS_DELAY\") // 437k\n    // .dropDuplicates(Seq(\"FL_DATE\", \"OP_CARRIER_AIRLINE_ID\", \"OP_CARRIER_FL_NUM\", \"ORIGIN_AIRPORT_ID\")) // 437k\n    // .withColumn(\"CRS_ELAPSED_TIME\", col(\"CRS_ELAPSED_TIME\").cast(\"int\")) // float -> int\n    // .withColumn(\"ARR_DELAY_NEW\", col(\"ARR_DELAY_NEW\").cast(\"int\"))\n    // .where(!(col(\"ARR_DELAY_NEW\") < -45)) // n'arrive jamais 45min en avance\n    // .where(col(\"ARR_DELAY_NEW\") < (5.3 * 60)) // 437k\n    // // .where(col(\"WEATHER_DELAY\") < (4.4 * 60)) // supprimer trop de ligne bizarrement ??"}, {"cell_type": "code", "execution_count": 4, "id": "594b441d-f911-4416-a58a-c1e4028b780e", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "4192912\n24\n"}, {"data": {"text/plain": "df_weather_clean = [WBAN: int, Date: int ... 22 more fields]\n"}, "metadata": {}, "output_type": "display_data", "source": "user"}, {"data": {"text/plain": "[WBAN: int, Date: int ... 22 more fields]"}, "execution_count": 4, "metadata": {}, "output_type": "execute_result"}], "source": "val df_weather_clean = df_weather_raw\n    .drop(df_weather_raw.columns.filter(colName => colName.endsWith(\"Flag\")) : _*)\n    .withColumn(\"Visibility\", trim(col(\"Visibility\")).cast(\"int\"))\n    .withColumn(\"RelativeHumidity\", trim(col(\"RelativeHumidity\")).cast(\"int\"))\n\n\nprintln(df_weather_clean.count())\nprintln(df_weather_clean.columns.size)"}, {"cell_type": "code", "execution_count": 62, "id": "abe64cf9-c8e1-4751-9642-66fe14cf8281", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "Visibility: [12], [null], [1], [13], [6], [3], [20], [40], [5], [19]\nRelativeHumidity: [31], [85], [65], [53], [78], [34], [81], [28], [76], [27]\n"}], "source": "println(\"Visibility: \"+df_weather_clean.select(\"Visibility\").distinct().take(10).mkString(\", \"))\nprintln(\"RelativeHumidity: \"+df_weather_clean.select(\"RelativeHumidity\").distinct().take(10).mkString(\", \"))\n\n// for (columnName <- df_weather_raw.columns) {\n//   println(\"10 of the disctinct values for \" + columnName + \": \" + df_weather_raw.select(columnName).distinct().take(10).mkString(\", \"))\n// }"}, {"cell_type": "code", "execution_count": 6, "id": "fa243e93-8e83-49be-b754-5b9132e065ca", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "10 of the disctinct values for WBAN: [3749], [3918], [3997], [4935], [3179], [4929], [3704], [3761], [3089], [3098]\n10 of the disctinct values for Date: [20120122], [20120127], [20120109], [20120103], [20120112], [20120123], [20120114], [20120108], [20120129], [20120131]\n10 of the disctinct values for Time: [833], [1645], [1238], [2122], [148], [1959], [1829], [1342], [2142], [2235]\n10 of the disctinct values for StationType: [12], [5], [15], [11], [0], [6]\n10 of the disctinct values for SkyCondition: [BKN120], [BKN050], [BKN013 BKN023 OVC030], [FEW090 SCT120], [BKN025 BKN031 OVC037], [FEW014 BKN023 OVC110], [SCT028 BKN047 OVC070], [FEW040 BKN120], [FEW022 OVC030], [BKN001 BKN006 OVC015]\n10 of the disctinct values for Visibility: [85], [12], [null], [1], [13], [6], [3], [20], [40], [5]\n10 of the disctinct values for WeatherType: [DZ], [-RASN BR], [UP FZFG], [+RA FG], [-SHRA BR], [VCTS -FZRA BR], [-RA SQ], [TSDZ], [-SNPL], [-FZRA SNPL BR]\n10 of the disctinct values for DryBulbFarenheit: [31], [85], [65], [53], [78], [34], [-1], [81], [28], [76]\n10 of the disctinct values for DryBulbCelsius: [9.1], [-20.3], [9.4], [-19.1], [-29.8], [-39.5], [18.0], [-7.9], [-8.8], [6.9]\n10 of the disctinct values for WetBulbFarenheit: [31], [65], [53], [-13], [-20], [34], [-1], [-17], [-21], [28]\n10 of the disctinct values for WetBulbCelsius: [-20.3], [9.1], [-19.1], [9.4], [-29.8], [-8.8], [-7.9], [6.9], [-17.7], [22.2]\n10 of the disctinct values for DewPointFarenheit: [31], [65], [53], [34], [-1], [81], [28], [76], [27], [26]\n10 of the disctinct values for DewPointCelsius: [-20.3], [9.1], [-19.1], [-29.8], [9.4], [-8.8], [-17.7], [-7.9], [22.2], [18.0]\n10 of the disctinct values for RelativeHumidity: [31], [85], [65], [53], [78], [34], [81], [28], [76], [26]\n10 of the disctinct values for WindSpeed: [31], [53], [34], [28], [26], [27], [44], [12], [22], [47]\n10 of the disctinct values for WindDirection: [210], [300], [350], [333], [330], [230], [190], [360], [140], [null]\n10 of the disctinct values for ValueForWindCharacter: [31], [53], [34], [101], [28], [76], [26], [44], [103], [91]\n10 of the disctinct values for StationPressure: [27.62], [29.12], [28.89], [30.64], [27.28], [24.77], [29.97], [30.28], [26.69], [23.95]\n10 of the disctinct values for PressureTendency: [null], [1], [6], [3], [5], [4], [8], [7], [2], [0]\n10 of the disctinct values for PressureChange: [31], [65], [53], [78], [34], [101], [81], [28], [76], [27]\n10 of the disctinct values for SeaLevelPressure: [30.64], [29.12], [28.89], [29.97], [30.28], [31.19], [29.91], [30.34], [29.77], [28.91]\n10 of the disctinct values for RecordType: [AA], [CRN05], [SP]\n10 of the disctinct values for HourlyPrecip: [0.34], [0.42], [0.15], [0.09], [0.38], [1.08], [0.48], [0.31], [0.43], [0.62]\n10 of the disctinct values for Altimeter: [30.64], [29.12], [28.89], [30.28], [29.97], [30.34], [29.91], [29.77], [28.91], [29.31]\n"}], "source": "for (columnName <- df_weather_clean.columns) {\n  println(\"10 of the disctinct values for \" + columnName + \": \" + df_weather_clean.select(columnName).distinct().take(10).mkString(\", \"))\n}"}, {"cell_type": "code", "execution_count": 8, "id": "73ad7000-4d4d-45e4-be30-93449a2c0a00", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "nb nulls WBAN: 0\nnb nulls Date: 0\nnb nulls Time: 0\nnb nulls StationType: 0\nnb nulls SkyCondition: 0\nnb nulls Visibility: 1831790\nnb nulls WeatherType: 3728635\nnb nulls DryBulbFarenheit: 138433\nnb nulls DryBulbCelsius: 24007\nnb nulls WetBulbFarenheit: 1895363\nnb nulls WetBulbCelsius: 1895363\nnb nulls DewPointFarenheit: 1933020\nnb nulls DewPointCelsius: 1858712\nnb nulls RelativeHumidity: 1895363\nnb nulls WindSpeed: 3355773\nnb nulls WindDirection: 1803373\nnb nulls ValueForWindCharacter: 3728936\nnb nulls StationPressure: 1833248\nnb nulls PressureTendency: 3904451\nnb nulls PressureChange: 3904451\nnb nulls SeaLevelPressure: 3374492\nnb nulls RecordType: 0\nnb nulls HourlyPrecip: 4096684\nnb nulls Altimeter: 1805797\n"}], "source": "val nbRows = df_weather_clean.count()\n\nfor (columnName <- df_weather_clean.columns) {\n    println(\"% nulls \" + columnName + \": \" + (df_weather_clean.filter(col(columnName).isNull || col(columnName) === \"\" || col(columnName) === \" \" || col(columnName) === \"null\").count() * 100.0 / nbRows)\n}"}, {"cell_type": "code", "execution_count": 10, "id": "89823e8c-bf94-485b-a4fa-e23c6915bc43", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "% nulls WBAN: 0.0\n% nulls Date: 0.0\n% nulls Time: 0.0\n% nulls StationType: 0.0\n% nulls SkyCondition: 0.0\n% nulls Visibility: 43.68777594187524\n% nulls WeatherType: 88.92709887543549\n% nulls DryBulbFarenheit: 3.3015956452222226\n% nulls DryBulbCelsius: 0.572561503794976\n% nulls WetBulbFarenheit: 45.20397756976536\n% nulls WetBulbCelsius: 45.20397756976536\n% nulls DewPointFarenheit: 46.102088476934405\n% nulls DewPointCelsius: 44.32985953437611\n% nulls RelativeHumidity: 45.20397756976536\n% nulls WindSpeed: 80.03442476255165\n% nulls WindDirection: 43.01003693852864\n% nulls ValueForWindCharacter: 88.93427765715093\n% nulls StationPressure: 43.72254891111476\n% nulls PressureTendency: 93.12027058998615\n% nulls PressureChange: 93.12027058998615\n% nulls SeaLevelPressure: 80.48086866597725\n% nulls RecordType: 0.0\n% nulls HourlyPrecip: 97.70498403019191\n% nulls Altimeter: 43.06784878862232\n"}, {"data": {"text/plain": "nbRows = 4192912\n"}, "metadata": {}, "output_type": "display_data", "source": "user"}, {"data": {"text/plain": "4192912"}, "execution_count": 10, "metadata": {}, "output_type": "execute_result"}], "source": "val nbRows = df_weather_clean.count()\n\nfor (columnName <- df_weather_clean.columns) {\n    println(\"% nulls \" + columnName + \": \" + (df_weather_clean.filter(col(columnName).isNull || col(columnName) === \"\" || col(columnName) === \" \" || col(columnName) === \"null\").count() * 100.0) / nbRows)\n}"}, {"cell_type": "code", "execution_count": null, "id": "13bf72a9-2702-4f7f-afec-f452cc127e87", "metadata": {}, "outputs": [], "source": ""}, {"cell_type": "code", "execution_count": null, "id": "7b38baa0-cae3-426a-b929-5458bb897def", "metadata": {}, "outputs": [], "source": ""}, {"cell_type": "code", "execution_count": null, "id": "cfa98969-523b-440c-8d9d-685910dab032", "metadata": {}, "outputs": [], "source": ""}, {"cell_type": "code", "execution_count": null, "id": "4023fd4d-64c1-4f41-b1d9-fdf26deddbdc", "metadata": {}, "outputs": [], "source": ""}, {"cell_type": "code", "execution_count": null, "id": "f7670d6b-67dd-4d69-a9b1-8be8def55b76", "metadata": {}, "outputs": [], "source": ""}, {"cell_type": "code", "execution_count": null, "id": "f59eafa6-9f7f-4b87-b908-b80f24d4c19d", "metadata": {}, "outputs": [], "source": ""}, {"cell_type": "markdown", "id": "8fca4cbf-424c-4095-abe1-23b560db5464", "metadata": {}, "source": "---\n\n# Backup"}, {"cell_type": "code", "execution_count": null, "id": "00001e09-8f61-47c5-9da3-0513233574e5", "metadata": {}, "outputs": [], "source": "import spark.sqlContext.implicits._\nimport org.apache.spark.sql.functions._\nval test = Seq((\"2019-01-23\"),(\"2019-06-24\"),(\"2019-09-20\")).toDF(\"date\")\n\ntest.show()\n\nimport java.sql.Timestamp\n\nval df = Seq(\n    (\"notebook\",    Timestamp.valueOf(\"2019-01-29 12:00:00\"), 2),\n    (\"notebook\",    Timestamp.valueOf(\"2019-01-01 00:00:00\"), 3),\n    (\"small_phone\", Timestamp.valueOf(\"2019-01-15 23:00:00\"), 4),\n    (\"small_phone\", Timestamp.valueOf(\"2019-01-01 09:00:00\"), 5)\n).toDF(\"device\", \"purchase_time\", \"minutes\").sort(\"device\",\"purchase_time\")\n\ndf.show()\n\ndf.withColumn(\"new\", to_timestamp(col(\"purchase_time\"))).show()\n\nval testbis = test.withColumn(\"date\", to_timestamp(col(\"date\"), \"yyyy-MM-dd\")) // HH:mm:ss\ntestbis.show()\n\ntestbis.printSchema()\n\nimport org.apache.spark.sql.functions.{add_months, date_add, _}\n\n\ntestbis.select(col(\"date\"), add_months(col(\"date\"), 3).as(\"add_months\")).show()\n\nimport spark.sqlContext.implicits._\nimport org.apache.spark.sql.functions._\n\ntestbis.add_months(lit(3)).show()\n\n\ndf.select(col(\"date\"),\n    add_months(col(\"date\"),3).as(\"add_months\"), // provide +ve value to add months\n    add_months(col(\"date\"),-3).as(\"sub_months\"), //provide -ve value to subtract months\n    date_add(col(\"date\"),4).as(\"date_add\"), // to add day\n    date_sub(col(\"date\"),4).as(\"date_sub\") //to substract day\n  ).show()\n\nimport org.apache.spark.sql.functions._\n\ndf_flights_clean\n    .withColumn(\"FL_DATE_TIME\", col(\"FL_DATE\")  + (col(\"CRS_DEP_TIME\") * 60))\n// df = df.withColumn(\"timestamp\", F.expr(\"from_unixtime(unix_timestamp(concat_ws(' ', date, time)) + (`additional_time(in mins)` * 60))\"))\n\n    .show()\n\nspark.sql(\"select input_timestamp, \" +\n    \"cast(input_timestamp as TIMESTAMP) + INTERVAL 2 hours as added_hours,\" +\n    \"cast(input_timestamp as TIMESTAMP) + INTERVAL 5 minutes as added_minutes,\" +\n    \"cast(input_timestamp as TIMESTAMP) + INTERVAL 55 seconds as added_seconds from AddTimeExample\"\n    )"}], "metadata": {"kernelspec": {"display_name": "Apache Toree - Scala", "language": "scala", "name": "apache_toree_scala"}, "language_info": {"codemirror_mode": "text/x-scala", "file_extension": ".scala", "mimetype": "text/x-scala", "name": "scala", "pygments_lexer": "scala", "version": "2.12.15"}}, "nbformat": 4, "nbformat_minor": 5}